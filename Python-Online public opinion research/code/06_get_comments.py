import requests
import pandas as pd
from datetime import datetime
from time import sleep

#é…ç½®å‚æ•°
API_KEY = 'AIzaSyB-HeztkGR5mKcqlTtvJQIlVQTDES2uGYk'
SEARCH_QUERY = 'China travel'
PUBLISHED_AFTER = '2023-05-01T00:00:00Z'
PUBLISHED_BEFORE = '2025-05-01T00:00:00Z'

#API ç«¯ç‚¹
search_url = 'https://www.googleapis.com/youtube/v3/search'
video_url = 'https://www.googleapis.com/youtube/v3/videos'

video_infos = []
next_page_token = None
seen_video_ids = set()

print("ğŸ“¡ å¼€å§‹æŠ“å–æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„è§†é¢‘...")

#1: éå†æœç´¢ç»“æœï¼Œè·å– videoId
while True:
    params = {
        'key': API_KEY,
        'q': SEARCH_QUERY,
        'part': 'snippet',
        'type': 'video',
        'maxResults': 50,
        'publishedAfter': PUBLISHED_AFTER,
        'publishedBefore': PUBLISHED_BEFORE,
    }
    if next_page_token:
        params['pageToken'] = next_page_token

    response = requests.get(search_url, params=params, timeout=30)
    data = response.json()

    video_ids = [item['id']['videoId'] for item in data.get('items', [])]
    video_ids = [vid for vid in video_ids if vid not in seen_video_ids]
    seen_video_ids.update(video_ids)

    if not video_ids:
        break

    #2: è·å–æ¯æ‰¹è§†é¢‘çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
    stats_params = {
        'key': API_KEY,
        'part': 'snippet,statistics',
        'id': ','.join(video_ids)
    }
    stats_response = requests.get(video_url, params=stats_params, timeout=30)
    stats_data = stats_response.json()

    for item in stats_data.get('items', []):
        try:
            views = int(item['statistics'].get('viewCount', 0))
            comments = int(item['statistics'].get('commentCount', 0))
            published_at = item['snippet']['publishedAt']
            video_infos.append({
                'videoId': item['id'],
                'title': item['snippet']['title'],
                'channel': item['snippet']['channelTitle'],
                'publishedAt': published_at[:10],
                'viewCount': views,
                'commentCount': comments,
                'url': f"https://www.youtube.com/watch?v={item['id']}"
            })
        except Exception as e:
            print(f"è·³è¿‡å¼‚å¸¸è§†é¢‘: {e}")

    next_page_token = data.get('nextPageToken')
    if not next_page_token:
        break

    sleep(0.3)  # é¿å…è§¦å‘é€Ÿç‡é™åˆ¶

print(f"âœ… å…±æŠ“å–è§†é¢‘æ•°ï¼š{len(video_infos)}")

#3: æŒ‰æ’­æ”¾é‡æ’åºï¼Œç­›é€‰å‰100æ¡
df = pd.DataFrame(video_infos)
df = df.sort_values(by='viewCount', ascending=False).head(100).reset_index(drop=True)

#4: ä¿å­˜ç»“æœ
df.to_csv("top100_videos.csv", index=False)
df['url'].to_csv("top100_urls.txt", index=False, header=False)

print("ğŸ“ å·²ä¿å­˜ä¸º top100_videos.csv å’Œ top100_urls.txt")
